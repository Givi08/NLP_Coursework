{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission <br>\n",
    "Final submission for NLP Corsework \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import PreProcessing\n",
    "pre_process = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zipf's Law Implementation\n",
    "processed = pre_process.set_n_grams(3, pre_process.zipfs_law(0.2, pre_process.lemmatize(pre_process.lowercase(pre_process.remove_stopwords(pre_process.remove_punctuation(reviews.review))))))\n",
    "\n",
    "## No Zipf's Law Implementation only do fo n_grams = 1\n",
    "# processed = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_stopwords(pre_process.lowercase(pre_process.remove_punctuation(reviews.review)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf_class_to_analyze import TFIDF\n",
    "tfidf = TFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_terms = {}\n",
    "#label_terms = []\n",
    "for review_id in range(len(processed)):\n",
    "    review_terms[review_id] = tfidf.get_terms(processed[review_id])\n",
    "\n",
    "all_terms = tfidf.collect_vocabulary(review_terms)\n",
    "\n",
    "#doc_vectors = tfidf.vectorize(review_terms, all_terms)\n",
    "\n",
    "doc_idfs = tfidf.calculate_idfs(all_terms, review_terms)\n",
    "doc_vectors = tfidf.vectorize_idf(review_terms, doc_idfs, all_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Dev Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_dev, y_train, y_test, y_dev = pre_process.set_data_splits(doc_vectors, list(reviews.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_classifier_2 import NB_Classifier\n",
    "nb = NB_Classifier(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.89 GiB for an array with shape (1422, 272343) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giova\\OneDrive\\Documenti\\GitHub\\NLP_Coursework\\Final_submission.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nb\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49marray(X_train), y_train)\n",
      "File \u001b[1;32mc:\\Users\\giova\\OneDrive\\Documenti\\GitHub\\NLP_Coursework\\nb_classifier_2.py:48\u001b[0m, in \u001b[0;36mNB_Classifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m label, samples \u001b[39min\u001b[39;00m separated\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_totals[label] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(samples)\n\u001b[0;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_probabilities[label] \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(samples) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(X))\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_counts[label] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(samples, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2321\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2322\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2324\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2325\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.89 GiB for an array with shape (1422, 272343) and data type float64"
     ]
    }
   ],
   "source": [
    "nb.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1422    0]\n",
      " [   0 1378]]\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = nb.predict(np.array(X_train))\n",
    "\n",
    "# Assuming 'y_true' is the true labels and 'y_pred' is the predicted labels\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_train, pred))\n",
    "print(\"Precision:\", precision_score(y_train, pred))\n",
    "print(\"Recall:\", recall_score(y_train, pred))\n",
    "print(\"F1 Score:\", f1_score(y_train, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[239  62]\n",
      " [ 81 218]]\n",
      "Accuracy: 0.7616666666666667\n",
      "Precision: 0.7785714285714286\n",
      "Recall: 0.7290969899665551\n",
      "F1 Score: 0.7530224525043179\n"
     ]
    }
   ],
   "source": [
    "pred_test = nb.predict(np.array(X_test))\n",
    "\n",
    "# Assuming 'y_true' is the true labels and 'y_pred' is the predicted labels\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_test))\n",
    "print(\"Precision:\", precision_score(y_test, pred_test))\n",
    "print(\"Recall:\", recall_score(y_test, pred_test))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1203  219]\n",
      " [ 202 1176]]\n",
      "Accuracy: 0.8496428571428571\n",
      "Precision: 0.843010752688172\n",
      "Recall: 0.8534107402031931\n",
      "F1 Score: 0.8481788676523622\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'y_true' is the true labels and 'y_pred' is the predicted labels\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_train, pred))\n",
    "print(\"Precision:\", precision_score(y_train, pred))\n",
    "print(\"Recall:\", recall_score(y_train, pred))\n",
    "print(\"F1 Score:\", f1_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[245  56]\n",
      " [ 55 244]]\n",
      "Accuracy: 0.815\n",
      "Precision: 0.8133333333333334\n",
      "Recall: 0.8160535117056856\n",
      "F1 Score: 0.8146911519198664\n"
     ]
    }
   ],
   "source": [
    "pred = mnb.predict(X_test)\n",
    "\n",
    "# Assuming 'y_true' is the true labels and 'y_pred' is the predicted labels\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred))\n",
    "print(\"Recall:\", recall_score(y_test, pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_log = SGDClassifier(loss='log', max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = sgd_log.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, predicts))\n",
    "print(\"Accuracy:\", accuracy_score(y_train, predicts))\n",
    "print(\"Precision:\", precision_score(y_train, predicts))\n",
    "print(\"Recall:\", recall_score(y_train, predicts))\n",
    "print(\"F1 Score:\", f1_score(y_train, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[233  68]\n",
      " [ 62 237]]\n",
      "Accuracy: 0.7833333333333333\n",
      "Precision: 0.7770491803278688\n",
      "Recall: 0.7926421404682275\n",
      "F1 Score: 0.7847682119205298\n"
     ]
    }
   ],
   "source": [
    "predicts = sgd_log.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predicts))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicts))\n",
    "print(\"Precision:\", precision_score(y_test, predicts))\n",
    "print(\"Recall:\", recall_score(y_test, predicts))\n",
    "print(\"F1 Score:\", f1_score(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_svm = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1419    3]\n",
      " [   2 1376]]\n",
      "Accuracy: 0.9982142857142857\n",
      "Precision: 0.9978245105148659\n",
      "Recall: 0.9985486211901307\n",
      "F1 Score: 0.9981864345302865\n"
     ]
    }
   ],
   "source": [
    "outp = sgd_svm.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, outp))\n",
    "print(\"Accuracy:\", accuracy_score(y_train, outp))\n",
    "print(\"Precision:\", precision_score(y_train, outp))\n",
    "print(\"Recall:\", recall_score(y_train, outp))\n",
    "print(\"F1 Score:\", f1_score(y_train, outp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[226  75]\n",
      " [ 72 227]]\n",
      "Accuracy: 0.755\n",
      "Precision: 0.7516556291390728\n",
      "Recall: 0.7591973244147158\n",
      "F1 Score: 0.7554076539101496\n"
     ]
    }
   ],
   "source": [
    "predicts = sgd_svm.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predicts))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicts))\n",
    "print(\"Precision:\", precision_score(y_test, predicts))\n",
    "print(\"Recall:\", recall_score(y_test, predicts))\n",
    "print(\"F1 Score:\", f1_score(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not run any of these cells it's quite messy. It saves the bert model locally so we can analyze performance in next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Imports for BERT model\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test. train dev split using same method as above\n",
    "X_train, X_test, X_dev, y_train, y_test, y_dev = pre_process.set_data_splits(reviews.review, reviews.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which version are you using?\n",
    "#assert 1 == 2\n",
    "\n",
    "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(X_dev), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, list(y_train))\n",
    "val_dataset = IMDbDataset(val_encodings, list(y_dev))\n",
    "test_dataset = IMDbDataset(test_encodings, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id2label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giova\\OneDrive\\Documenti\\GitHub\\NLP_Coursework\\Final_submission.ipynb Cell 42\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForSequenceClassification\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m, num_labels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, id2label\u001b[39m=\u001b[39mid2label, label2id\u001b[39m=\u001b[39mlabel2id\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id2label' is not defined"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bae88339fd48b28fea9e1a599d383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7087, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}\n",
      "{'loss': 0.7079, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.11}\n",
      "{'loss': 0.7217, 'learning_rate': 3e-06, 'epoch': 0.17}\n",
      "{'loss': 0.6852, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 0.6813, 'learning_rate': 5e-06, 'epoch': 0.29}\n",
      "{'loss': 0.6638, 'learning_rate': 6e-06, 'epoch': 0.34}\n",
      "{'loss': 0.6478, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.4}\n",
      "{'loss': 0.6207, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.46}\n",
      "{'loss': 0.5881, 'learning_rate': 9e-06, 'epoch': 0.51}\n",
      "{'loss': 0.5614, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 0.556, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3925, 'learning_rate': 1.2e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3736, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4339, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3734, 'learning_rate': 1.5e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3617, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.91}\n",
      "{'loss': 0.289, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3701, 'learning_rate': 1.8e-05, 'epoch': 1.03}\n",
      "{'loss': 0.335, 'learning_rate': 1.9e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3185, 'learning_rate': 2e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2167, 'learning_rate': 2.1e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2298, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2158, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.31}\n",
      "{'loss': 0.54, 'learning_rate': 2.4e-05, 'epoch': 1.37}\n",
      "{'loss': 0.195, 'learning_rate': 2.5e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2441, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2921, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2255, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.6}\n",
      "{'loss': 0.253, 'learning_rate': 2.9e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3129, 'learning_rate': 3e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2816, 'learning_rate': 3.1e-05, 'epoch': 1.77}\n",
      "{'loss': 0.2245, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2547, 'learning_rate': 3.3e-05, 'epoch': 1.89}\n",
      "{'loss': 0.1771, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3272, 'learning_rate': 3.5e-05, 'epoch': 2.0}\n",
      "{'loss': 0.2531, 'learning_rate': 3.6e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1708, 'learning_rate': 3.7e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2426, 'learning_rate': 3.8e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1859, 'learning_rate': 3.9000000000000006e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1169, 'learning_rate': 4e-05, 'epoch': 2.29}\n",
      "{'loss': 0.2079, 'learning_rate': 4.1e-05, 'epoch': 2.34}\n",
      "{'loss': 0.2213, 'learning_rate': 4.2e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1166, 'learning_rate': 4.3e-05, 'epoch': 2.46}\n",
      "{'loss': 0.1499, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.51}\n",
      "{'loss': 0.2042, 'learning_rate': 4.5e-05, 'epoch': 2.57}\n",
      "{'loss': 0.2949, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.63}\n",
      "{'loss': 0.2383, 'learning_rate': 4.7e-05, 'epoch': 2.69}\n",
      "{'loss': 0.2211, 'learning_rate': 4.8e-05, 'epoch': 2.74}\n",
      "{'loss': 0.1105, 'learning_rate': 4.9e-05, 'epoch': 2.8}\n",
      "{'loss': 0.2364, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
      "{'loss': 0.1945, 'learning_rate': 3e-05, 'epoch': 2.91}\n",
      "{'loss': 0.1448, 'learning_rate': 1e-05, 'epoch': 2.97}\n",
      "{'train_runtime': 6857.364, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.077, 'train_loss': 0.3391809720084781, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=525, training_loss=0.3391809720084781, metrics={'train_runtime': 6857.364, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.077, 'train_loss': 0.3391809720084781, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NO Metrics Compute\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    no_cuda= False\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to('cuda')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Metrics computed\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # load_best_model_at_end=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00311a33c09a49098aa53e58275d4c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b5043a0e2a4e57a70eb605d00e2ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28091785311698914, 'eval_accuracy': 0.9, 'eval_runtime': 25.9731, 'eval_samples_per_second': 23.101, 'eval_steps_per_second': 1.463, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b7cc94f2234a36b6a6a8d3ec02d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3185114562511444, 'eval_accuracy': 0.9, 'eval_runtime': 26.1432, 'eval_samples_per_second': 22.951, 'eval_steps_per_second': 1.454, 'epoch': 2.0}\n",
      "{'train_runtime': 4686.3677, 'train_samples_per_second': 1.195, 'train_steps_per_second': 0.075, 'train_loss': 0.3038702828543527, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=0.3038702828543527, metrics={'train_runtime': 4686.3677, 'train_samples_per_second': 1.195, 'train_steps_per_second': 0.075, 'train_loss': 0.3038702828543527, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"results/checkpoint-500/\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"results/checkpoint-500/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "## Change here for train/test/dev set\n",
    "for w in list(X_test):\n",
    "    inputs = tokenizer(w, return_tensors=\"pt\", truncation= True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    pred.append(1 if model.config.id2label[predicted_class_id] == 'LABEL_1' else 0)\n",
    "    #print(model.config.id2label[predicted_class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2800, 600]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giova\\OneDrive\\Documenti\\GitHub\\NLP_Coursework\\Final_submission.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#Y140sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, confusion_matrix(y_train, pred))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#Y140sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(y_train, pred))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giova/OneDrive/Documenti/GitHub/NLP_Coursework/Final_submission.ipynb#Y140sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrecision:\u001b[39m\u001b[39m\"\u001b[39m, precision_score(y_train, pred))\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2800, 600]"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_train, pred))\n",
    "print(\"Precision:\", precision_score(y_train, pred))\n",
    "print(\"Recall:\", recall_score(y_train, pred))\n",
    "print(\"F1 Score:\", f1_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[287  14]\n",
      " [ 63 236]]\n",
      "Accuracy: 0.8716666666666667\n",
      "Precision: 0.944\n",
      "Recall: 0.7892976588628763\n",
      "F1 Score: 0.8597449908925319\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred))\n",
    "print(\"Recall:\", recall_score(y_test, pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cased Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "cased_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238d903797a94cdb947e0298e7131d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33df66a630a45059998be032715130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2918759286403656, 'eval_accuracy': 0.8833333333333333, 'eval_runtime': 26.5647, 'eval_samples_per_second': 22.586, 'eval_steps_per_second': 1.43, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246bd7bc50714640ae9bfbdd72c1489a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30336907505989075, 'eval_accuracy': 0.8883333333333333, 'eval_runtime': 26.4312, 'eval_samples_per_second': 22.7, 'eval_steps_per_second': 1.438, 'epoch': 2.0}\n",
      "{'train_runtime': 4622.5317, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.076, 'train_loss': 0.3330478777204241, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=0.3330478777204241, metrics={'train_runtime': 4622.5317, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.076, 'train_loss': 0.3330478777204241, 'epoch': 2.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/cased\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "cased_model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\") #.to('cuda')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=cased_model,\n",
    "    args=training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "imported_model = AutoModelForSequenceClassification.from_pretrained('results/cased/checkpoint-350/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "# Change here for train/test/dev split\n",
    "for w in list(X_test):\n",
    "    inputs = tokenizer(w, return_tensors=\"pt\", truncation= True)\n",
    "    with torch.no_grad():\n",
    "        logits = imported_model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicts.append(1 if imported_model.config.id2label[predicted_class_id]== 'LABEL_1' else 0)\n",
    "    #print(model.config.id2label[predicted_class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[287  14]\n",
      " [ 63 236]]\n",
      "Accuracy: 0.8716666666666667\n",
      "Precision: 0.944\n",
      "Recall: 0.7892976588628763\n",
      "F1 Score: 0.8597449908925319\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred))\n",
    "print(\"Recall:\", recall_score(y_test, pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 Iter evaluation <br>\n",
    "Final submission for NLP Corsework \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import PreProcessing\n",
    "pre_process = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed1 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.lowercase(pre_process.remove_punctuation(reviews.review))))))\n",
    "\n",
    "processed2 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.lowercase(reviews.review)))))\n",
    "processed3 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.remove_punctuation(reviews.review)))))\n",
    "#processed4 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.lowercase(pre_process.remove_punctuation(reviews.review)))))\n",
    "#processed5 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.lowercase(pre_process.remove_punctuation(reviews.review)))))\n",
    "\n",
    "processed6 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.remove_stopwords(reviews.review))))\n",
    "# processed7 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.lowercase(reviews.review))))\n",
    "# processed8 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(pre_process.remove_punctuation(reviews.review))))\n",
    "# processed9 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.lowercase(reviews.review))))\n",
    "# processed10 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.remove_stopwords(pre_process.remove_punctuation(reviews.review))))\n",
    "# processed11 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.lowercase(pre_process.remove_punctuation(reviews.review))))\n",
    "\n",
    "# processed12 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.lemmatize(reviews.review)))\n",
    "# processed13 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.remove_stopwords(reviews.review)))\n",
    "# processed14 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.lowercase(reviews.review)))\n",
    "# processed15 = pre_process.set_n_grams(1, pre_process.lemmatize(pre_process.remove_punctuation(reviews.review)))\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "processed16 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.remove_stopwords(pre_process.lowercase(pre_process.remove_punctuation(reviews.review))))))\n",
    "\n",
    "processed17 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.remove_stopwords(pre_process.lowercase(reviews.review)))))\n",
    "processed18 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.remove_stopwords(pre_process.remove_punctuation(reviews.review)))))\n",
    "# processed19 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.lowercase(pre_process.remove_punctuation(reviews.review)))))\n",
    "# processed20 = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_stopwords(pre_process.lowercase(pre_process.remove_punctuation(reviews.review)))))\n",
    "\n",
    "processed21 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.remove_stopwords(reviews.review))))\n",
    "# processed22 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.lowercase(reviews.review))))\n",
    "# processed23 = pre_process.set_n_grams(2, pre_process.zipfs_law(0.05, pre_process.stem(pre_process.remove_punctuation(reviews.review))))\n",
    "# processed24 = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_stopwords(pre_process.lowercase(reviews.review))))\n",
    "# processed25 = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_stopwords(pre_process.remove_punctuation(reviews.review))))\n",
    "# processed26 = pre_process.set_n_grams(1, pre_process.stem(pre_process.lowercase(pre_process.remove_punctuation(reviews.review))))\n",
    "\n",
    "# processed27 = pre_process.set_n_grams(1, pre_process.zipfs_law(0.05, pre_process.stem(reviews.review)))\n",
    "# processed28 = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_stopwords(reviews.review)))\n",
    "# processed29 = pre_process.set_n_grams(1, pre_process.stem(pre_process.lowercase(reviews.review)))\n",
    "# processed30 = pre_process.set_n_grams(1, pre_process.stem(pre_process.remove_punctuation(reviews.review)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possibilities = []\n",
    "all_possibilities.append(processed1)\n",
    "all_possibilities.append(processed2)\n",
    "all_possibilities.append(processed3)\n",
    "# all_possibilities.append(processed4)\n",
    "#all_possibilities.append(processed5)\n",
    "all_possibilities.append(processed6)\n",
    "# all_possibilities.append(processed7)\n",
    "# all_possibilities.append(processed8)\n",
    "# all_possibilities.append(processed9)\n",
    "# all_possibilities.append(processed10)\n",
    "# all_possibilities.append(processed11)\n",
    "#all_possibilities.append(processed12)\n",
    "# all_possibilities.append(processed13)\n",
    "# all_possibilities.append(processed14)\n",
    "# all_possibilities.append(processed15)\n",
    "all_possibilities.append(processed16)\n",
    "all_possibilities.append(processed17)\n",
    "all_possibilities.append(processed18)\n",
    "# all_possibilities.append(processed19)\n",
    "# all_possibilities.append(processed20)\n",
    "all_possibilities.append(processed21)\n",
    "# all_possibilities.append(processed22)\n",
    "# all_possibilities.append(processed23)\n",
    "# all_possibilities.append(processed24)\n",
    "# all_possibilities.append(processed25)\n",
    "# all_possibilities.append(processed26)\n",
    "# all_possibilities.append(processed27)\n",
    "# all_possibilities.append(processed28)\n",
    "# all_possibilities.append(processed29)\n",
    "# all_possibilities.append(processed30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf_class_to_analyze import TFIDF\n",
    "tfidf = TFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "for i in range(8): #range(len(all_possibilities)):\n",
    "    review_terms = {}\n",
    "    for review_id in range(len(all_possibilities[i])):\n",
    "        review_terms[review_id] = tfidf.get_terms(all_possibilities[i][review_id])\n",
    "\n",
    "    all_terms = tfidf.collect_vocabulary(review_terms)\n",
    "\n",
    "\n",
    "    doc_idfs = tfidf.calculate_idfs(all_terms, review_terms)\n",
    "    doc_vectors = tfidf.vectorize_idf(review_terms, doc_idfs, all_terms)\n",
    "    all_vectors.append(doc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Dev Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_dev, y_train, y_test, y_dev = [],[],[],[],[],[]\n",
    "for i in range(8):\n",
    "    X_train.append([])\n",
    "    X_test.append([])\n",
    "    X_dev.append([])\n",
    "    y_train.append([])\n",
    "    y_test.append([])\n",
    "    y_dev.append([])\n",
    "\n",
    "for i in range(10):\n",
    "    X_train[i], X_test[i], X_dev[i], y_train[i], y_test[i], y_dev[i] = pre_process.set_data_splits(all_vectors[i], list(reviews.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_classifier_2 import NB_Classifier\n",
    "nb = NB_Classifier(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy: 0.7966666666666666\n",
      "Precision: 0.7940199335548173\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.7966666666666667\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Accuracy: 0.8066666666666666\n",
      "Precision: 0.8122866894197952\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.8040540540540541\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Accuracy: 0.785\n",
      "Precision: 0.7814569536423841\n",
      "Recall: 0.7892976588628763\n",
      "F1 Score: 0.7853577371048254\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Accuracy: 0.785\n",
      "Precision: 0.8148148148148148\n",
      "Recall: 0.7357859531772575\n",
      "F1 Score: 0.7732864674868188\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Accuracy: 0.7983333333333333\n",
      "Precision: 0.8296296296296296\n",
      "Recall: 0.7491638795986622\n",
      "F1 Score: 0.7873462214411249\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Accuracy: 0.7983333333333333\n",
      "Precision: 0.8345864661654135\n",
      "Recall: 0.7424749163879598\n",
      "F1 Score: 0.7858407079646017\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Accuracy: 0.805\n",
      "Precision: 0.8095238095238095\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.8026981450252951\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Accuracy: 0.7816666666666666\n",
      "Precision: 0.8111111111111111\n",
      "Recall: 0.7324414715719063\n",
      "F1 Score: 0.7697715289982425\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Accuracy: 0.7866666666666666\n",
      "Precision: 0.8226415094339623\n",
      "Recall: 0.7290969899665551\n",
      "F1 Score: 0.7730496453900709\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Accuracy: 0.7983333333333333\n",
      "Precision: 0.8345864661654135\n",
      "Recall: 0.7424749163879598\n",
      "F1 Score: 0.7858407079646017\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    nb = NB_Classifier(alpha=1)\n",
    "    nb.fit(np.array(X_train[i]), y_train[i])\n",
    "    pred_test = nb.predict(np.array(X_test[i]))\n",
    "    print(i)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test[i], pred_test))\n",
    "    print(\"Precision:\", precision_score(y_test[i], pred_test))\n",
    "    print(\"Recall:\", recall_score(y_test[i], pred_test))\n",
    "    print(\"F1 Score:\", f1_score(y_test[i], pred_test))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy: 0.815\n",
      "Precision: 0.8133333333333334\n",
      "Recall: 0.8160535117056856\n",
      "F1 Score: 0.8146911519198664\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Accuracy: 0.8033333333333333\n",
      "Precision: 0.7967213114754098\n",
      "Recall: 0.8127090301003345\n",
      "F1 Score: 0.8046357615894039\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Accuracy: 0.82\n",
      "Precision: 0.8215488215488216\n",
      "Recall: 0.8160535117056856\n",
      "F1 Score: 0.8187919463087248\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Accuracy: 0.8\n",
      "Precision: 0.7993311036789298\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.7993311036789298\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Accuracy: 0.7966666666666666\n",
      "Precision: 0.8127208480565371\n",
      "Recall: 0.7692307692307693\n",
      "F1 Score: 0.7903780068728523\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Accuracy: 0.8166666666666667\n",
      "Precision: 0.8225255972696246\n",
      "Recall: 0.8060200668896321\n",
      "F1 Score: 0.8141891891891893\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8013468013468014\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.7986577181208054\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Accuracy: 0.805\n",
      "Precision: 0.7993421052631579\n",
      "Recall: 0.8127090301003345\n",
      "F1 Score: 0.8059701492537312\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Accuracy: 0.7816666666666666\n",
      "Precision: 0.8\n",
      "Recall: 0.7491638795986622\n",
      "F1 Score: 0.773747841105354\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Accuracy: 0.805\n",
      "Precision: 0.8137931034482758\n",
      "Recall: 0.7892976588628763\n",
      "F1 Score: 0.801358234295416\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "for i in range(10):\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(np.array(X_train[i]), y_train[i])\n",
    "    pred_test = mnb.predict(np.array(X_test[i]))\n",
    "    print(i)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test[i], pred_test))\n",
    "    print(\"Precision:\", precision_score(y_test[i], pred_test))\n",
    "    print(\"Recall:\", recall_score(y_test[i], pred_test))\n",
    "    print(\"F1 Score:\", f1_score(y_test[i], pred_test))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy: 0.7633333333333333\n",
      "Precision: 0.7940074906367042\n",
      "Recall: 0.7090301003344481\n",
      "F1 Score: 0.7491166077738515\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Accuracy: 0.7583333333333333\n",
      "Precision: 0.7730496453900709\n",
      "Recall: 0.7290969899665551\n",
      "F1 Score: 0.7504302925989671\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Accuracy: 0.7483333333333333\n",
      "Precision: 0.7517006802721088\n",
      "Recall: 0.7391304347826086\n",
      "F1 Score: 0.7453625632377741\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Accuracy: 0.8016666666666666\n",
      "Precision: 0.7903225806451613\n",
      "Recall: 0.8193979933110368\n",
      "F1 Score: 0.8045977011494253\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Accuracy: 0.815\n",
      "Precision: 0.8241379310344827\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.8115449915110355\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Accuracy: 0.7983333333333333\n",
      "Precision: 0.7986577181208053\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.7973199329983249\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Accuracy: 0.7566666666666667\n",
      "Precision: 0.7593220338983051\n",
      "Recall: 0.7491638795986622\n",
      "F1 Score: 0.7542087542087542\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Accuracy: 0.8116666666666666\n",
      "Precision: 0.803921568627451\n",
      "Recall: 0.822742474916388\n",
      "F1 Score: 0.8132231404958677\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Accuracy: 0.7966666666666666\n",
      "Precision: 0.7845659163987139\n",
      "Recall: 0.8160535117056856\n",
      "F1 Score: 0.8\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Accuracy: 0.7983333333333333\n",
      "Precision: 0.7986577181208053\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.7973199329983249\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_log = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42)\n",
    "for i in range(10):\n",
    "    sgd_log = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42)\n",
    "    sgd_log.fit(np.array(X_train[i]), y_train[i])\n",
    "    pred_test = sgd_log.predict(np.array(X_test[i]))\n",
    "    print(i)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test[i], pred_test))\n",
    "    print(\"Precision:\", precision_score(y_test[i], pred_test))\n",
    "    print(\"Recall:\", recall_score(y_test[i], pred_test))\n",
    "    print(\"F1 Score:\", f1_score(y_test[i], pred_test))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy: 0.775\n",
      "Precision: 0.7847222222222222\n",
      "Recall: 0.7558528428093646\n",
      "F1 Score: 0.7700170357751277\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Accuracy: 0.765\n",
      "Precision: 0.746875\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.7722132471728596\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Accuracy: 0.7683333333333333\n",
      "Precision: 0.7816901408450704\n",
      "Recall: 0.7424749163879598\n",
      "F1 Score: 0.7615780445969125\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Accuracy: 0.8066666666666666\n",
      "Precision: 0.8122866894197952\n",
      "Recall: 0.7959866220735786\n",
      "F1 Score: 0.8040540540540541\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Accuracy: 0.8083333333333333\n",
      "Precision: 0.8129251700680272\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.806070826306914\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Accuracy: 0.82\n",
      "Precision: 0.8327526132404182\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.8156996587030717\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Accuracy: 0.765\n",
      "Precision: 0.7705479452054794\n",
      "Recall: 0.7525083612040134\n",
      "F1 Score: 0.7614213197969543\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Accuracy: 0.81\n",
      "Precision: 0.8222996515679443\n",
      "Recall: 0.7892976588628763\n",
      "F1 Score: 0.8054607508532424\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Accuracy: 0.8083333333333333\n",
      "Precision: 0.8026315789473685\n",
      "Recall: 0.8160535117056856\n",
      "F1 Score: 0.8092868988391377\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Accuracy: 0.82\n",
      "Precision: 0.8327526132404182\n",
      "Recall: 0.7993311036789298\n",
      "F1 Score: 0.8156996587030717\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sgd_svm =  SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)\n",
    "    sgd_svm.fit(np.array(X_train[i]), y_train[i])\n",
    "    pred_test = sgd_svm.predict(np.array(X_test[i]))\n",
    "    print(i)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test[i], pred_test))\n",
    "    print(\"Precision:\", precision_score(y_test[i], pred_test))\n",
    "    print(\"Recall:\", recall_score(y_test[i], pred_test))\n",
    "    print(\"F1 Score:\", f1_score(y_test[i], pred_test))\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
